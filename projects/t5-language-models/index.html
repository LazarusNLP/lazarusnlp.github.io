
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="This project focuses on pre-training a T5 (Text-to-Text Transfer Transformer) model specifically for the Indonesian language, using nanoT5 as its training framework. Our aim is to provide fully open-source, budget-constrained, sequence-to-sequence language models for Indonesia that are on-par with state-of-the-art models!">
      
      
      
        <link rel="canonical" href="https://lazarusnlp.github.io/projects/t5-language-models/">
      
      
        <link rel="prev" href="../sentence-embeddings/">
      
      
        <link rel="next" href="../machine-translation/">
      
      
      <link rel="icon" href="../../assets/images/logo_web.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.13">
    
    
      
        <title>Indonesian T5 Language Models - Lazarus NLP</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.7e359304.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="Indonesian T5 Language Models - Lazarus NLP" >
      
        <meta  property="og:description"  content="This project focuses on pre-training a T5 (Text-to-Text Transfer Transformer) model specifically for the Indonesian language, using nanoT5 as its training framework. Our aim is to provide fully open-source, budget-constrained, sequence-to-sequence language models for Indonesia that are on-par with state-of-the-art models!" >
      
        <meta  property="og:image"  content="https://lazarusnlp.github.io/assets/images/social/projects/t5-language-models.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://lazarusnlp.github.io/projects/t5-language-models/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="Indonesian T5 Language Models - Lazarus NLP" >
      
        <meta  name="twitter:description"  content="This project focuses on pre-training a T5 (Text-to-Text Transfer Transformer) model specifically for the Indonesian language, using nanoT5 as its training framework. Our aim is to provide fully open-source, budget-constrained, sequence-to-sequence language models for Indonesia that are on-par with state-of-the-art models!" >
      
        <meta  name="twitter:image"  content="https://lazarusnlp.github.io/assets/images/social/projects/t5-language-models.png" >
      
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="black">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pre-trained-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Lazarus NLP" class="md-header__button md-logo" aria-label="Lazarus NLP" data-md-component="logo">
      
  <img src="../../assets/images/logo_web.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Lazarus NLP
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Indonesian T5 Language Models
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="black"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="black"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/lazarusnlp/lazarusnlp.github.io/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blogs/launch/" class="md-tabs__link">
          
  
  Blogs

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../nusabert/" class="md-tabs__link">
          
  
  Projects

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="https://github.com/LazarusNLP" class="md-tabs__link">
        
  
    
  
  GitHub

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="https://huggingface.co/LazarusNLP" class="md-tabs__link">
        
  
    
  
  ðŸ¤— Hugging Face

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Lazarus NLP" class="md-nav__button md-logo" aria-label="Lazarus NLP" data-md-component="logo">
      
  <img src="../../assets/images/logo_web.png" alt="logo">

    </a>
    Lazarus NLP
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/lazarusnlp/lazarusnlp.github.io/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Blogs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Blogs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blogs/launch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Launching LazarusNLP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blogs/bible_alignment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bible Alignment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../blogs/accents_and_languages/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Indonesian Accents and Regional Languages
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Projects
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Projects
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nusabert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NusaBERT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sentence-embeddings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sentence Embeddings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Indonesian T5 Language Models
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Indonesian T5 Language Models
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pre-trained-models" class="md-nav__link">
    <span class="md-ellipsis">
      Pre-trained Models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    <span class="md-ellipsis">
      Results
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#indosum" class="md-nav__link">
    <span class="md-ellipsis">
      IndoSum
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#liputan6-canonical" class="md-nav__link">
    <span class="md-ellipsis">
      Liputan6 Canonical
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#liputan6-extreme" class="md-nav__link">
    <span class="md-ellipsis">
      Liputan6 Extreme
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tydiqa" class="md-nav__link">
    <span class="md-ellipsis">
      TyDiQA
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xpersona" class="md-nav__link">
    <span class="md-ellipsis">
      XPersona
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dataset" class="md-nav__link">
    <span class="md-ellipsis">
      Dataset
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#train-sentencepiece-tokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      Train SentencePiece Tokenizer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pre-train-t5" class="md-nav__link">
    <span class="md-ellipsis">
      Pre-train T5
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pre-train T5">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#experiments" class="md-nav__link">
    <span class="md-ellipsis">
      Experiments
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fine-tune-t5" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-tune T5
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Fine-tune T5">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#summarization" class="md-nav__link">
    <span class="md-ellipsis">
      Summarization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#question-answering" class="md-nav__link">
    <span class="md-ellipsis">
      Question-Answering
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chit-chat" class="md-nav__link">
    <span class="md-ellipsis">
      Chit-chat
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#acknowledgements" class="md-nav__link">
    <span class="md-ellipsis">
      Acknowledgements
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#credits" class="md-nav__link">
    <span class="md-ellipsis">
      Credits
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../machine-translation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Machine Translation
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/LazarusNLP" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GitHub
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://huggingface.co/LazarusNLP" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ðŸ¤— Hugging Face
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Indonesian T5 Language Models</h1>

<div class="grid cards">
<ul>
<li><a href="https://github.com/LazarusNLP/IndoT5/"><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33.85 0 1.71.11 2.5.33 1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2Z"/></svg></span> GitHub Repository</a></li>
<li><a href="https://huggingface.co/collections/LazarusNLP/indonesian-t5-language-models-65c1b9a0f6342b3eb3d6d450">ðŸ¤— HuggingFace Collection</a></li>
</ul>
</div>
<div align="center">

<a href="https://huggingface.co/collections/LazarusNLP/indonesian-t5-language-models-65c1b9a0f6342b3eb3d6d450"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Collections-yellow"></img></a>

</div>

<p>This project focuses on pre-training a <a href="https://arxiv.org/abs/1910.10683">T5</a> (Text-to-Text Transfer Transformer) model specifically for the Indonesian language, using <a href="https://github.com/PiotrNawrot/nanoT5">nanoT5</a> as its training framework. Our aim is to provide fully open-source, budget-constrained, sequence-to-sequence language models for Indonesia that are on-par with state-of-the-art models!</p>
<p align="center">
    <img src="https://raw.githubusercontent.com/LazarusNLP/IndoT5/main/assets/logo.png" alt="logo" width="400"/>
</p>

<h2 id="pre-trained-models">Pre-trained Models</h2>
<table>
<thead>
<tr>
<th>Model</th>
<th style="text-align: center;">#params</th>
<th>Dataset</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://huggingface.co/LazarusNLP/IndoNanoT5-base">LazarusNLP/IndoNanoT5-base</a></td>
<td style="text-align: center;">248M</td>
<td><a href="https://huggingface.co/datasets/uonlp/CulturaX">uonlp/CulturaX</a></td>
</tr>
</tbody>
</table>
<h2 id="results">Results</h2>
<p>We evaluate our models on <a href="https://github.com/IndoNLP/indonlg">IndoNLG</a>, which consists of multiple downsteam generation tasks in Indonesian. The dataset also supports Javanese and Sundanese, but as our model is currently monolingual, we fine-tune on Indonesian tasks only.</p>
<blockquote>
<p>IndoNLG baseline results are obtained from the <a href="https://aclanthology.org/2021.emnlp-main.699/">official IndoNLG paper</a>.</p>
</blockquote>
<h3 id="indosum">IndoSum</h3>
<table>
<thead>
<tr>
<th>Model</th>
<th style="text-align: center;">#params</th>
<th style="text-align: center;">R1 â†‘</th>
<th style="text-align: center;">R2 â†‘</th>
<th style="text-align: center;">RL â†‘</th>
</tr>
</thead>
<tbody>
<tr>
<td>Scratch</td>
<td style="text-align: center;">132M</td>
<td style="text-align: center;">70.52</td>
<td style="text-align: center;">65.43</td>
<td style="text-align: center;">68.35</td>
</tr>
<tr>
<td>mBART Large</td>
<td style="text-align: center;">610M</td>
<td style="text-align: center;">74.65</td>
<td style="text-align: center;">70.43</td>
<td style="text-align: center;">72.54</td>
</tr>
<tr>
<td>mT5 Small</td>
<td style="text-align: center;">300M</td>
<td style="text-align: center;">74.04</td>
<td style="text-align: center;">69.64</td>
<td style="text-align: center;">71.89</td>
</tr>
<tr>
<td>IndoBART</td>
<td style="text-align: center;">132M</td>
<td style="text-align: center;">70.67</td>
<td style="text-align: center;">65.59</td>
<td style="text-align: center;">68.18</td>
</tr>
<tr>
<td>IndoGPT</td>
<td style="text-align: center;">117M</td>
<td style="text-align: center;">74.49</td>
<td style="text-align: center;">70.34</td>
<td style="text-align: center;">72.46</td>
</tr>
<tr>
<td><em>Our work</em></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><a href="https://huggingface.co/LazarusNLP/IndoNanoT5-base">LazarusNLP/IndoNanoT5-base</a></td>
<td style="text-align: center;">248M</td>
<td style="text-align: center;"><strong>75.29</strong></td>
<td style="text-align: center;"><strong>71.23</strong></td>
<td style="text-align: center;"><strong>73.30</strong></td>
</tr>
</tbody>
</table>
<h3 id="liputan6-canonical">Liputan6 Canonical</h3>
<table>
<thead>
<tr>
<th>Model</th>
<th style="text-align: center;">#params</th>
<th style="text-align: center;">R1 â†‘</th>
<th style="text-align: center;">R2 â†‘</th>
<th style="text-align: center;">RL â†‘</th>
</tr>
</thead>
<tbody>
<tr>
<td>Scratch</td>
<td style="text-align: center;">132M</td>
<td style="text-align: center;">38.14</td>
<td style="text-align: center;">20.67</td>
<td style="text-align: center;">31.85</td>
</tr>
<tr>
<td>See et al. (2017)</td>
<td style="text-align: center;">22M</td>
<td style="text-align: center;">36.09</td>
<td style="text-align: center;">19.19</td>
<td style="text-align: center;">29.81</td>
</tr>
<tr>
<td>Koto et al. (2020)</td>
<td style="text-align: center;">153M</td>
<td style="text-align: center;"><strong>41.06</strong></td>
<td style="text-align: center;"><strong>22.83</strong></td>
<td style="text-align: center;"><strong>34.23</strong></td>
</tr>
<tr>
<td>mBART Large</td>
<td style="text-align: center;">610M</td>
<td style="text-align: center;">39.17</td>
<td style="text-align: center;">21.75</td>
<td style="text-align: center;">32.85</td>
</tr>
<tr>
<td>mT5 Small</td>
<td style="text-align: center;">300M</td>
<td style="text-align: center;">39.69</td>
<td style="text-align: center;">22.03</td>
<td style="text-align: center;">33.28</td>
</tr>
<tr>
<td>IndoBART</td>
<td style="text-align: center;">132M</td>
<td style="text-align: center;">39.87</td>
<td style="text-align: center;">22.24</td>
<td style="text-align: center;">33.50</td>
</tr>
<tr>
<td>IndoGPT</td>
<td style="text-align: center;">117M</td>
<td style="text-align: center;">37.41</td>
<td style="text-align: center;">20.61</td>
<td style="text-align: center;">31.54</td>
</tr>
<tr>
<td><em>Our work</em></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><a href="https://huggingface.co/LazarusNLP/IndoNanoT5-base">LazarusNLP/IndoNanoT5-base</a></td>
<td style="text-align: center;">248M</td>
<td style="text-align: center;">39.76</td>
<td style="text-align: center;">22.29</td>
<td style="text-align: center;">33.46</td>
</tr>
</tbody>
</table>
<h3 id="liputan6-extreme">Liputan6 Extreme</h3>
<table>
<thead>
<tr>
<th>Model</th>
<th style="text-align: center;">#params</th>
<th style="text-align: center;">R1 â†‘</th>
<th style="text-align: center;">R2 â†‘</th>
<th style="text-align: center;">RL â†‘</th>
</tr>
</thead>
<tbody>
<tr>
<td>Scratch</td>
<td style="text-align: center;">132M</td>
<td style="text-align: center;">32.47</td>
<td style="text-align: center;">13.45</td>
<td style="text-align: center;">25.52</td>
</tr>
<tr>
<td>See et al. (2017)</td>
<td style="text-align: center;">22M</td>
<td style="text-align: center;">30.39</td>
<td style="text-align: center;">12.03</td>
<td style="text-align: center;">23.55</td>
</tr>
<tr>
<td>Koto et al. (2020)</td>
<td style="text-align: center;">153M</td>
<td style="text-align: center;"><strong>34.84</strong></td>
<td style="text-align: center;"><strong>15.03</strong></td>
<td style="text-align: center;"><strong>27.44</strong></td>
</tr>
<tr>
<td>mBART Large</td>
<td style="text-align: center;">610M</td>
<td style="text-align: center;">32.87</td>
<td style="text-align: center;">13.79</td>
<td style="text-align: center;">25.91</td>
</tr>
<tr>
<td>mT5 Small</td>
<td style="text-align: center;">300M</td>
<td style="text-align: center;">33.37</td>
<td style="text-align: center;">14.01</td>
<td style="text-align: center;">26.21</td>
</tr>
<tr>
<td>IndoBART</td>
<td style="text-align: center;">132M</td>
<td style="text-align: center;">33.58</td>
<td style="text-align: center;">14.45</td>
<td style="text-align: center;">26.68</td>
</tr>
<tr>
<td>IndoGPT</td>
<td style="text-align: center;">117M</td>
<td style="text-align: center;">31.45</td>
<td style="text-align: center;">13.09</td>
<td style="text-align: center;">24.91</td>
</tr>
<tr>
<td><em>Our work</em></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><a href="https://huggingface.co/LazarusNLP/IndoNanoT5-base">LazarusNLP/IndoNanoT5-base</a></td>
<td style="text-align: center;">248M</td>
<td style="text-align: center;">33.23</td>
<td style="text-align: center;">14.17</td>
<td style="text-align: center;">26.21</td>
</tr>
</tbody>
</table>
<h3 id="tydiqa">TyDiQA</h3>
<table>
<thead>
<tr>
<th>Model</th>
<th style="text-align: center;">#params</th>
<th style="text-align: center;">EM â†‘</th>
<th style="text-align: center;">F1 â†‘</th>
</tr>
</thead>
<tbody>
<tr>
<td>Scratch</td>
<td style="text-align: center;">132M</td>
<td style="text-align: center;">21.40</td>
<td style="text-align: center;">29.77</td>
</tr>
<tr>
<td>mBART Large</td>
<td style="text-align: center;">610M</td>
<td style="text-align: center;"><strong>62.69</strong></td>
<td style="text-align: center;"><strong>76.41</strong></td>
</tr>
<tr>
<td>mT5 Small</td>
<td style="text-align: center;">300M</td>
<td style="text-align: center;">35.67</td>
<td style="text-align: center;">51.90</td>
</tr>
<tr>
<td>IndoBART</td>
<td style="text-align: center;">132M</td>
<td style="text-align: center;">57.31</td>
<td style="text-align: center;">69.59</td>
</tr>
<tr>
<td>IndoGPT</td>
<td style="text-align: center;">117M</td>
<td style="text-align: center;">50.18</td>
<td style="text-align: center;">63.97</td>
</tr>
<tr>
<td><em>Our work</em></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><a href="https://huggingface.co/LazarusNLP/IndoNanoT5-base">LazarusNLP/IndoNanoT5-base</a></td>
<td style="text-align: center;">248M</td>
<td style="text-align: center;">58.94</td>
<td style="text-align: center;">72.19</td>
</tr>
</tbody>
</table>
<h3 id="xpersona">XPersona</h3>
<table>
<thead>
<tr>
<th>Model</th>
<th style="text-align: center;">#params</th>
<th style="text-align: center;">SacreBLEU â†‘</th>
<th style="text-align: center;">BLEU â†‘</th>
</tr>
</thead>
<tbody>
<tr>
<td>Scratch</td>
<td style="text-align: center;">132M</td>
<td style="text-align: center;">1.86</td>
<td style="text-align: center;">1.86</td>
</tr>
<tr>
<td>CausalBERT <span class="arithmatex">\(^\dagger\)</span></td>
<td style="text-align: center;">110M</td>
<td style="text-align: center;">2.24</td>
<td style="text-align: center;">2.23</td>
</tr>
<tr>
<td>mBART Large</td>
<td style="text-align: center;">610M</td>
<td style="text-align: center;">2.57</td>
<td style="text-align: center;">2.56</td>
</tr>
<tr>
<td>mT5 Small</td>
<td style="text-align: center;">300M</td>
<td style="text-align: center;">1.90</td>
<td style="text-align: center;">1.89</td>
</tr>
<tr>
<td>IndoBART</td>
<td style="text-align: center;">132M</td>
<td style="text-align: center;">2.93</td>
<td style="text-align: center;">2.93</td>
</tr>
<tr>
<td>IndoGPT</td>
<td style="text-align: center;">117M</td>
<td style="text-align: center;">2.02</td>
<td style="text-align: center;">2.02</td>
</tr>
<tr>
<td><em>Our work</em> <span class="arithmatex">\(^\dagger\)</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td><a href="https://huggingface.co/LazarusNLP/IndoNanoT5-base">LazarusNLP/IndoNanoT5-base</a></td>
<td style="text-align: center;">248M</td>
<td style="text-align: center;"><strong>4.07</strong></td>
<td style="text-align: center;"><strong>4.07</strong></td>
</tr>
</tbody>
</table>
<blockquote>
<p><span class="arithmatex">\(^\dagger\)</span> Our models are trained with additional persona information, just like the original CausalBERT baseline. The remaining models are not trained with persona information. Our findings suggest that persona information is crucial for this task; serving a similar purpose to system prompts in recent LLM development.</p>
</blockquote>
<h2 id="installation">Installation</h2>
<div class="language-sh highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/LazarusNLP/IndoT5.git
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="nb">cd</span><span class="w"> </span>IndoT5
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>git<span class="w"> </span>submodule<span class="w"> </span>update<span class="w"> </span>--init<span class="w"> </span><span class="c1"># clone nanoT5 submodule</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>nanoT5/requirements.txt
</span></code></pre></div>
<h2 id="dataset">Dataset</h2>
<p>We leverage the existing <a href="https://huggingface.co/datasets/uonlp/CulturaX">uonlp/CulturaX</a> dataset which contains 23M Indonesian documents, collected and cleaned from the <a href="https://oscar-corpus.com/">OSCAR</a> corpora and <a href="https://huggingface.co/datasets/mc4">mc4</a>. We selected this dataset as it is sufficiently large and has been deduplicated. More details can be found in their dataset card.</p>
<p>Since this dataset is rather large, we utilize the dataset streaming feature of Hugging Face datasets, which is thankfully also supported in nanoT5. This feature is likewise usable during tokenizer training.</p>
<h2 id="train-sentencepiece-tokenizer">Train SentencePiece Tokenizer</h2>
<p>We first need to train a SentencePiece tokenizer on our pre-pretraining corpus. We followed the uncased T5 tokenizer training implementation from <a href="https://github.com/huggingface/transformers/tree/main/examples/flax/language-modeling#train-tokenizer-2">HuggingFace</a>. We then initialize a T5 config based on <a href="https://huggingface.co/google/t5-v1_1-base">google/t5-v1_1-base</a> and the newly trained tokenizer. Both the tokenizer and the config are then saved for loading later. </p>
<p>To train the SentencePiece tokenizer, run <code>train_tokenizer.py</code> with the desired arguments:</p>
<div class="language-sh highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>python<span class="w"> </span>train_tokenizer.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="w">    </span>--vocab-size<span class="w"> </span><span class="m">32000</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="w">    </span>--dataset-name<span class="w"> </span>uonlp/CulturaX<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="w">    </span>--dataset-config<span class="w"> </span>id<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="w">    </span>--output-dir<span class="w"> </span>outputs/indonesian-t5-base/<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="w">    </span>--base-model-config<span class="w"> </span>google/t5-v1_1-base<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="w">    </span>--hf-repo-id<span class="w"> </span>LazarusNLP/IndoNanoT5-base
</span></code></pre></div>
<p>It took us about an hour to train the tokenizer.</p>
<h2 id="pre-train-t5">Pre-train T5</h2>
<p>NanoT5 handles most of the training process and exposes a clean API to pre-train a T5 model from scratch. We follow their default training configuration, with the exception of a lower learning rate which is specific to our dataset. Other than that, running pre-training is as simple as:</p>
<div class="language-sh highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>python<span class="w"> </span>-m<span class="w"> </span>nanoT5.main<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="w">    </span>optim.name<span class="o">=</span>adamwscale<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="w">    </span>optim.lr_scheduler<span class="o">=</span>cosine<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="w">    </span>optim.base_lr<span class="o">=</span>5e-3<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="w">    </span>model.name<span class="o">=</span>LazarusNLP/IndoNanoT5-base<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="w">    </span>model.compile<span class="o">=</span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="w">    </span>data.num_workers<span class="o">=</span><span class="m">16</span>
</span></code></pre></div>
<p>We achieved a negative log-likelihood loss of 2.082 and an accuracy of 57.4% on a heldout subset (1%) of the pre-training corpus.</p>
<h3 id="experiments">Experiments</h3>
<p>We experimented with different learning rates, optimizers, and layer initialization strategies. Whilst we found that the default scaled AdamW optimizer worked best for our baseline results, we aim to further improve the results. Specifically, we aim to experiment with:</p>
<ul class="task-list">
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled checked/><span class="task-list-indicator"></span></label> Initializing <code>lm_head</code> weights with <code>std=1/sqrt(d_model)</code></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled/><span class="task-list-indicator"></span></label> (Unscaled) AdamW Optimizer</li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled/><span class="task-list-indicator"></span></label> <a href="https://pytorch.org/docs/2.2/generated/torch.optim.NAdam.html#torch.optim.NAdam">NAdamW Optimizer</a></li>
<li class="task-list-item"><label class="task-list-control"><input type="checkbox" disabled/><span class="task-list-indicator"></span></label> <a href="https://arxiv.org/abs/1802.09568">Shampoo</a> and <a href="https://openreview.net/forum?id=8j9hz8DVi8">CASPR</a> Optimizers</li>
</ul>
<p>This growing list of ideas stem from a fruitful discussion <a href="https://github.com/PiotrNawrot/nanoT5/issues/25">here</a>.</p>
<details>
  <summary>Training Losses</summary>

  <img src="https://raw.githubusercontent.com/LazarusNLP/IndoT5/main/assets/training_loss.png"/>
</details>

<h2 id="fine-tune-t5">Fine-tune T5</h2>
<p>NanoT5 supports fine-tuning to a downstream dataset like Super Natural-Instructions (SNI). However, since this requires further customization of fine-tuning code to other downstream datasets, we opted to develop our own fine-tuning script based on Hugging Face's <a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch">sample fine-tuning code</a>.</p>
<p>In particular, we developed fine-tuning scripts for 3 IndoNLG tasks, namely: summarization, question-answering, and chit-chat (conversational), which you can find in <a href="https://github.com/LazarusNLP/IndoT5/tree/main/scripts">scripts</a>.</p>
<h3 id="summarization">Summarization</h3>
<p>To fine-tune for summarization, run the following command and modify accordingly:</p>
<div class="language-sh highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>python<span class="w"> </span>scripts/run_summarization.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="w">    </span>--model-checkpoint<span class="w"> </span>LazarusNLP/IndoNanoT5-base<span class="w"> </span><span class="se">\ </span><span class="c1"># pre-trained model checkpoint</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="w">    </span>--dataset-name<span class="w"> </span>LazarusNLP/indonlg<span class="w"> </span><span class="se">\ </span><span class="c1"># Hugging Face ðŸ¤— dataset name</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="w">    </span>--dataset-config<span class="w"> </span>indosum<span class="w"> </span><span class="se">\ </span><span class="c1"># dataset config</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="w">    </span>--input-column-name<span class="w"> </span>input<span class="w"> </span><span class="se">\ </span><span class="c1"># input column (text passage) name in dataset</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a><span class="w">    </span>--target-column-name<span class="w"> </span>target<span class="w"> </span><span class="se">\ </span><span class="c1"># target column (summary) name in dataset</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a><span class="w">    </span>--input-max-length<span class="w"> </span><span class="m">512</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a><span class="w">    </span>--target-max-length<span class="w"> </span><span class="m">512</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a><span class="w">    </span>--num-beams<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\ </span><span class="c1"># beam width during beam search</span>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a><span class="w">    </span>--output-dir<span class="w"> </span>outputs/indo-nanot5-indosum<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a><span class="w">    </span>--num-train-epochs<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a><span class="w">    </span>--optim<span class="w"> </span>adamw_torch_fused<span class="w"> </span><span class="se">\ </span><span class="c1"># any optimizer supported in Hugging Face ðŸ¤— transformers</span>
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a><span class="w">    </span>--learning-rate<span class="w"> </span>1e-3<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a><span class="w">    </span>--weight-decay<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a><span class="w">    </span>--per-device-train-batch-size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a><span class="w">    </span>--per-device-eval-batch-size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a><span class="w">    </span>--hub-model-id<span class="w"> </span>LazarusNLP/IndoNanoT5-base-IndoSum<span class="w"> </span><span class="c1"># Hugging Face ðŸ¤— Hub repo name</span>
</span></code></pre></div>
<p>IndoNLG summarization recipes are provided <a href="https://github.com/LazarusNLP/IndoT5/blob/main/run_summarization.sh">here</a>.</p>
<h3 id="question-answering">Question-Answering</h3>
<p>To fine-tune for question-answering, run the following command and modify accordingly:</p>
<div class="language-sh highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>python<span class="w"> </span>scripts/run_qa.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="w">    </span>--model-checkpoint<span class="w"> </span>LazarusNLP/IndoNanoT5-base<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="w">    </span>--dataset-name<span class="w"> </span>LazarusNLP/indonlg<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="w">    </span>--dataset-config<span class="w"> </span>question_answering<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="w">    </span>--context-column-name<span class="w"> </span>context<span class="w"> </span><span class="se">\ </span><span class="c1"># context/passage column name</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="w">    </span>--question-column-name<span class="w"> </span>input<span class="w"> </span><span class="se">\ </span><span class="c1"># question column name</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="w">    </span>--answer-column-name<span class="w"> </span>references<span class="w"> </span><span class="se">\ </span><span class="c1"># answer column name, must be list</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a><span class="w">    </span>--id-column-name<span class="w"> </span>gem_id<span class="w"> </span><span class="se">\ </span><span class="c1"># question-answer pair id</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a><span class="w">    </span>--input-max-length<span class="w"> </span><span class="m">512</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a><span class="w">    </span>--target-max-length<span class="w"> </span><span class="m">512</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a><span class="w">    </span>--num-beams<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a><span class="w">    </span>--output-dir<span class="w"> </span>outputs/indo-nanot5-tydiqa<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a><span class="w">    </span>--num-train-epochs<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a><span class="w">    </span>--optim<span class="w"> </span>adamw_torch_fused<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a><span class="w">    </span>--learning-rate<span class="w"> </span>1e-5<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a><span class="w">    </span>--weight-decay<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a><span class="w">    </span>--per-device-train-batch-size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a><span class="w">    </span>--per-device-eval-batch-size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a><span class="w">    </span>--hub-model-id<span class="w"> </span>LazarusNLP/IndoNanoT5-base-TyDiQA
</span></code></pre></div>
<p>IndoNLG question-answering recipe is provided <a href="https://github.com/LazarusNLP/IndoT5/blob/main/run_qa.sh">here</a>.</p>
<h3 id="chit-chat">Chit-chat</h3>
<p>To fine-tune for chit-chat, run the following command and modify accordingly:</p>
<div class="language-sh highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>python<span class="w"> </span>scripts/run_chitchat.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="w">    </span>--model-checkpoint<span class="w"> </span>LazarusNLP/IndoNanoT5-base<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="w">    </span>--dataset-name<span class="w"> </span>LazarusNLP/indonlg<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="w">    </span>--dataset-config<span class="w"> </span>xpersona<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="w">    </span>--context-column-name<span class="w"> </span>context<span class="w"> </span><span class="se">\ </span><span class="c1"># context/persona column name</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="w">    </span>--question-column-name<span class="w"> </span>input<span class="w"> </span><span class="se">\ </span><span class="c1"># conversation history/dialogues column name</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span class="w">    </span>--answer-column-name<span class="w"> </span>references<span class="w"> </span><span class="se">\ </span><span class="c1"># response column name</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a><span class="w">    </span>--use-persona<span class="w"> </span><span class="se">\ </span><span class="c1"># whether to use persona or not</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a><span class="w">    </span>--input-max-length<span class="w"> </span><span class="m">512</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a><span class="w">    </span>--target-max-length<span class="w"> </span><span class="m">512</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a><span class="w">    </span>--num-beams<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a><span class="w">    </span>--output-dir<span class="w"> </span>outputs/indo-nanot5-xpersona<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a><span class="w">    </span>--num-train-epochs<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a><span class="w">    </span>--optim<span class="w"> </span>adamw_torch_fused<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-15"><a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a><span class="w">    </span>--learning-rate<span class="w"> </span>1e-5<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-16"><a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a><span class="w">    </span>--weight-decay<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-17"><a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a><span class="w">    </span>--per-device-train-batch-size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-18"><a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a><span class="w">    </span>--per-device-eval-batch-size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-19"><a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a><span class="w">    </span>--hub-model-id<span class="w"> </span>LazarusNLP/IndoNanoT5-base-XPersona
</span></code></pre></div>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>Thanks to <a href="https://github.com/PiotrNawrot">@PiotrNawrot</a> and <a href="https://github.com/Birch-san">@Birch-san</a> for the engaging discussion and ideas.</p>
<h2 id="references">References</h2>
<div class="language-bibtex highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="nc">@article</span><span class="p">{</span><span class="nl">Nawrot2023nanoT5AP</span><span class="p">,</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{nanoT5: A PyTorch Framework for Pre-training and Fine-tuning T5-style Models with Limited Resources}</span><span class="p">,</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Piotr Nawrot}</span><span class="p">,</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{ArXiv}</span><span class="p">,</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2023}</span><span class="p">,</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="w">  </span><span class="na">volume</span><span class="p">=</span><span class="s">{abs/2309.02373}</span><span class="p">,</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a><span class="p">}</span>
</span></code></pre></div>
<h2 id="credits">Credits</h2>
<p>IndoT5 is developed with love by:</p>
<div style="display: flex;">
<a href="https://github.com/anantoj">
    <img src="https://github.com/anantoj.png" alt="GitHub Profile" style="border-radius: 50%;width: 64px;border: solid 0px #fff;margin:0 4px;">
</a>

<a href="https://github.com/DavidSamuell">
    <img src="https://github.com/DavidSamuell.png" alt="GitHub Profile" style="border-radius: 50%;width: 64px;border: solid 0px #fff;margin:0 4px;">
</a>

<a href="https://github.com/stevenlimcorn">
    <img src="https://github.com/stevenlimcorn.png" alt="GitHub Profile" style="border-radius: 50%;width: 64px;border: solid 0px #fff;margin:0 4px;">
</a>

<a href="https://github.com/w11wo">
    <img src="https://github.com/w11wo.png" alt="GitHub Profile" style="border-radius: 50%;width: 64px;border: solid 0px #fff;margin:0 4px;">
</a>
</div>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.top", "toc.integrate"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8d2eff1.min.js"></script>
      
        <script src="../../javascripts/katex.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>